{
    "summary": "The code defines a Conv2d class with attributes and initializes weights and biases. It also includes three functions, `map_pixels`, `unmap_pixels`, and `conv2d`, for scaling, convolution operation, and padding based on kernel width.",
    "details": [
        {
            "comment": "This code defines a Conv2d class that extends torch.nn.Module and implements a 2D convolutional layer using the nn.Conv2d module from PyTorch. The class has several attributes including number of input channels (n_in), number of output channels (n_out), kernel width (kw), use_float16 for whether to use float16 or float32, device for tensor storage location, and requires_grad for whether the parameters should be tracked during backpropagation. The class initializes the weight matrix (self.w) with normal distribution and bias (self.b) as zeros. It also has a forward method that applies the convolution operation on the input tensor (x).",
            "location": "\"/media/root/Toshiba XG3/works/DALL-E/docs/src/dall_e/utils.py\":0-31",
            "content": "import attr\nimport math\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nlogit_laplace_eps: float = 0.1\n@attr.s(eq=False)\nclass Conv2d(nn.Module):\n\tn_in:  int = attr.ib(validator=lambda i, a, x: x >= 1)\n\tn_out: int = attr.ib(validator=lambda i, a, x: x >= 1)\n\tkw:    int = attr.ib(validator=lambda i, a, x: x >= 1 and x % 2 == 1)\n\tuse_float16:   bool         = attr.ib(default=True)\n\tdevice:        torch.device = attr.ib(default=torch.device('cpu'))\n\trequires_grad: bool         = attr.ib(default=False)\n\tdef __attrs_post_init__(self) -> None:\n\t\tsuper().__init__()\n\t\tw = torch.empty((self.n_out, self.n_in, self.kw, self.kw), dtype=torch.float32,\n\t\t\tdevice=self.device, requires_grad=self.requires_grad)\n\t\tw.normal_(std=1 / math.sqrt(self.n_in * self.kw ** 2))\n\t\tb = torch.zeros((self.n_out,), dtype=torch.float32, device=self.device,\n\t\t\trequires_grad=self.requires_grad)\n\t\tself.w, self.b = nn.Parameter(w), nn.Parameter(b)\n\tdef forward(self, x: torch.Tensor) -> torch.Tensor:\n\t\tif self.use_float16 and 'cuda' in self.w.device.type:"
        },
        {
            "comment": "The code defines three functions: `map_pixels`, `unmap_pixels`, and `conv2d`. The `map_pixels` function scales the input tensor by a factor and adds a constant to it. It also checks if the input tensor is 4-dimensional and has the correct data type (float). Similarly, the `unmap_pixels` function scales and shifts the input tensor, and ensures the correct dimensions and data type. The `conv2d` function applies a convolution operation on the input tensor with specified weights and biases, and handles the padding based on the kernel width.",
            "location": "\"/media/root/Toshiba XG3/works/DALL-E/docs/src/dall_e/utils.py\":32-58",
            "content": "\t\t\tif x.dtype != torch.float16:\n\t\t\t\tx = x.half()\n\t\t\tw, b = self.w.half(), self.b.half()\n\t\telse:\n\t\t\tif x.dtype != torch.float32:\n\t\t\t\tx = x.float()\n\t\t\tw, b = self.w, self.b\n\t\treturn F.conv2d(x, w, b, padding=(self.kw - 1) // 2)\ndef map_pixels(x: torch.Tensor) -> torch.Tensor:\n\tif len(x.shape) != 4:\n\t\traise ValueError('expected input to be 4d')\n\tif x.dtype != torch.float:\n\t\traise ValueError('expected input to have type float')\n\treturn (1 - 2 * logit_laplace_eps) * x + logit_laplace_eps\ndef unmap_pixels(x: torch.Tensor) -> torch.Tensor:\n\tif len(x.shape) != 4:\n\t\traise ValueError('expected input to be 4d')\n\tif x.dtype != torch.float:\n\t\traise ValueError('expected input to have type float')\n\treturn torch.clamp((x - logit_laplace_eps) / (1 - 2 * logit_laplace_eps), 0, 1)"
        }
    ]
}