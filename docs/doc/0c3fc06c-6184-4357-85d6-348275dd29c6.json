{
    "summary": "The code defines two classes, \"EncoderBlock\" and \"Encoder\", for neural network modules with 4 groups of 2 blocks each, using residual paths. It encodes input, performs max pooling, checks errors, and has various attributes for computation.",
    "details": [
        {
            "comment": "This code defines a class named \"EncoderBlock\" which is a module for an encoder block in the neural network. It takes input parameters such as the number of input features (n_in), output features (n_out), and layers (n_layers). The module also has properties like device, requires_grad, and initializes instance variables n_hid, post_gain. It uses a partial function to make a convolution layer and creates an identity path and residual path for the encoder block.",
            "location": "\"/media/root/Toshiba XG3/works/DALL-E/docs/src/dall_e/encoder.py\":0-30",
            "content": "import attr\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom collections  import OrderedDict\nfrom functools    import partial\nfrom dall_e.utils import Conv2d\n@attr.s(eq=False, repr=False)\nclass EncoderBlock(nn.Module):\n\tn_in:     int = attr.ib(validator=lambda i, a, x: x >= 1)\n\tn_out:    int = attr.ib(validator=lambda i, a, x: x >= 1 and x % 4 ==0)\n\tn_layers: int = attr.ib(validator=lambda i, a, x: x >= 1)\n\tdevice:        torch.device = attr.ib(default=None)\n\trequires_grad: bool         = attr.ib(default=False)\n\tdef __attrs_post_init__(self) -> None:\n\t\tsuper().__init__()\n\t\tself.n_hid = self.n_out // 4\n\t\tself.post_gain = 1 / (self.n_layers ** 2)\n\t\tmake_conv     = partial(Conv2d, device=self.device, requires_grad=self.requires_grad)\n\t\tself.id_path  = make_conv(self.n_in, self.n_out, 1) if self.n_in != self.n_out else nn.Identity()\n\t\tself.res_path = nn.Sequential(OrderedDict([\n\t\t\t\t('relu_1', nn.ReLU()),\n\t\t\t\t('conv_1', make_conv(self.n_in,  self.n_hid, 3)),\n\t\t\t\t('relu_2', nn.ReLU()),"
        },
        {
            "comment": "This code defines a class called \"Encoder\" which is a type of neural network module. It has 4 groups, each group containing 2 blocks of convolutional layers and activation functions. The input is passed through the identity path and the residual path, then their sum is returned as output. The Encoder class also has several attributes such as number of hidden units, number of block per group, input channels, vocabulary size, device to run on, requires gradient computation, and use mixed precision.",
            "location": "\"/media/root/Toshiba XG3/works/DALL-E/docs/src/dall_e/encoder.py\":31-55",
            "content": "\t\t\t\t('conv_2', make_conv(self.n_hid, self.n_hid, 3)),\n\t\t\t\t('relu_3', nn.ReLU()),\n\t\t\t\t('conv_3', make_conv(self.n_hid, self.n_hid, 3)),\n\t\t\t\t('relu_4', nn.ReLU()),\n\t\t\t\t('conv_4', make_conv(self.n_hid, self.n_out, 1)),]))\n\tdef forward(self, x: torch.Tensor) -> torch.Tensor:\n\t\treturn self.id_path(x) + self.post_gain * self.res_path(x)\n@attr.s(eq=False, repr=False)\nclass Encoder(nn.Module):\n\tgroup_count:     int = 4\n\tn_hid:           int = attr.ib(default=256,  validator=lambda i, a, x: x >= 64)\n\tn_blk_per_group: int = attr.ib(default=2,    validator=lambda i, a, x: x >= 1)\n\tinput_channels:  int = attr.ib(default=3,    validator=lambda i, a, x: x >= 1)\n\tvocab_size:      int = attr.ib(default=8192, validator=lambda i, a, x: x >= 512)\n\tdevice:              torch.device = attr.ib(default=torch.device('cpu'))\n\trequires_grad:       bool         = attr.ib(default=False)\n\tuse_mixed_precision: bool         = attr.ib(default=True)\n\tdef __attrs_post_init__(self) -> None:\n\t\tsuper().__init__()\n\t\tblk_range  = range(self.n_blk_per_group)"
        },
        {
            "comment": "This code is creating a neural network encoder with multiple blocks. It consists of four groups, each with different number of layers and hidden size. Each group has a series of EncoderBlocks followed by a max pooling operation. The input channel size is defined based on the current block and group configuration.",
            "location": "\"/media/root/Toshiba XG3/works/DALL-E/docs/src/dall_e/encoder.py\":56-76",
            "content": "\t\tn_layers   = self.group_count * self.n_blk_per_group\n\t\tmake_conv  = partial(Conv2d, device=self.device, requires_grad=self.requires_grad)\n\t\tmake_blk   = partial(EncoderBlock, n_layers=n_layers, device=self.device,\n\t\t\t\trequires_grad=self.requires_grad)\n\t\tself.blocks = nn.Sequential(OrderedDict([\n\t\t\t('input', make_conv(self.input_channels, 1 * self.n_hid, 7)),\n\t\t\t('group_1', nn.Sequential(OrderedDict([\n\t\t\t\t*[(f'block_{i + 1}', make_blk(1 * self.n_hid, 1 * self.n_hid)) for i in blk_range],\n\t\t\t\t('pool', nn.MaxPool2d(kernel_size=2)),\n\t\t\t]))),\n\t\t\t('group_2', nn.Sequential(OrderedDict([\n\t\t\t\t*[(f'block_{i + 1}', make_blk(1 * self.n_hid if i == 0 else 2 * self.n_hid, 2 * self.n_hid)) for i in blk_range],\n\t\t\t\t('pool', nn.MaxPool2d(kernel_size=2)),\n\t\t\t]))),\n\t\t\t('group_3', nn.Sequential(OrderedDict([\n\t\t\t\t*[(f'block_{i + 1}', make_blk(2 * self.n_hid if i == 0 else 4 * self.n_hid, 4 * self.n_hid)) for i in blk_range],\n\t\t\t\t('pool', nn.MaxPool2d(kernel_size=2)),\n\t\t\t]))),\n\t\t\t('group_4', nn.Sequential(OrderedDict([\n\t\t\t\t"
        },
        {
            "comment": "The code defines a neural network module that takes an input tensor and passes it through multiple blocks of convolutional layers. The output is then processed by another set of convolutional layers before returning the final result. The function also includes error checks for the shape, number of channels, and data type of the input tensor to ensure proper functioning.",
            "location": "\"/media/root/Toshiba XG3/works/DALL-E/docs/src/dall_e/encoder.py\":76-92",
            "content": "*[(f'block_{i + 1}', make_blk(4 * self.n_hid if i == 0 else 8 * self.n_hid, 8 * self.n_hid)) for i in blk_range],\n\t\t\t]))),\n\t\t\t('output', nn.Sequential(OrderedDict([\n\t\t\t\t('relu', nn.ReLU()),\n\t\t\t\t('conv', make_conv(8 * self.n_hid, self.vocab_size, 1, use_float16=False)),\n\t\t\t]))),\n\t\t]))\n\tdef forward(self, x: torch.Tensor) -> torch.Tensor:\n\t\tif len(x.shape) != 4:\n\t\t\traise ValueError(f'input shape {x.shape} is not 4d')\n\t\tif x.shape[1] != self.input_channels:\n\t\t\traise ValueError(f'input has {x.shape[1]} channels but model built for {self.input_channels}')\n\t\tif x.dtype != torch.float32:\n\t\t\traise ValueError('input must have dtype torch.float32')\n\t\treturn self.blocks(x)"
        }
    ]
}